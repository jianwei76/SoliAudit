{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "#init logging\n",
    "log_level = logging.INFO\n",
    "logging.basicConfig(level=log_level,\n",
    "        format=\"%(asctime)s.%(msecs)03d [%(levelname)s] [%(module)s] %(message)s\", datefmt=\"%H:%M:%S\")\n",
    "\n",
    "ALL_VULS = ['Underflow','Overflow','Multisig','CallDepth','TOD','TimeDep','Reentracy','AssertFail',\n",
    "            'TxOrigin','CheckEffects','InlineAssembly','BlockTimestamp','LowlevelCalls','BlockHash','SelfDestruct']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:25:52.014 [INFO] [<ipython-input-3-5b546898050e>] Loading the cached data 'data-cache.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEF_DATAFILE = 'data-cache.csv'\n",
    "\n",
    "def newer(f1, f2):\n",
    "    return os.path.getmtime(f1) > os.path.getmtime(f2)\n",
    "\n",
    "# be careful, it's no easy way to check if vol + ft = data,\n",
    "# we just check if cache data is newer than vol and ft\n",
    "def getData(volfile, ftfile, reload=False):\n",
    "\n",
    "    if not reload and os.path.exists(DEF_DATAFILE) \\\n",
    "            and newer(DEF_DATAFILE, volfile) and newer(DEF_DATAFILE, ftfile):\n",
    "\n",
    "        logging.info(\"Loading the cached data '%s'\" % DEF_DATAFILE);\n",
    "        data = pd.read_csv(DEF_DATAFILE, index_col=0)\n",
    "    else:\n",
    "        logging.info(\"Creating the data...\")\n",
    "\n",
    "        y_mapping = {'r': 1, 'o': 1, 'x': 0}\n",
    "\n",
    "        data = pd.merge(\n",
    "                left_index=True,\n",
    "                left=pd.read_csv(volfile, index_col=0).replace(y_mapping),\n",
    "                right_index=True,\n",
    "                right=pd.read_csv(ftfile, index_col=0),\n",
    "                how='inner')\n",
    "        data.drop_duplicates(inplace=True)\n",
    "        logging.info(\"Saving the data to '%s'\" % DEF_DATAFILE);\n",
    "        data.to_csv(DEF_DATAFILE)\n",
    "\n",
    "    return data\n",
    "\n",
    "# prepare data\n",
    "data = getData('vols.csv', 'ft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17979, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def stratifiedSplit(df, colname):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_idx, test_idx in split.split(df, df[colname]):\n",
    "        return df.iloc[train_idx], df.iloc[test_idx]\n",
    "\n",
    "def splitData(data, volname):\n",
    "    #train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    train_set, test_set = stratifiedSplit(data, volname)\n",
    "\n",
    "    X_train = train_set['Opcodes'].values\n",
    "    y_train = train_set[volname].values\n",
    "    X_test = test_set['Opcodes'].values\n",
    "    y_test = test_set[volname].values\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "__vulname = vul = 'TOD'\n",
    "data_sets = splitData(data, vul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperparamKeeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data__label</th>\n",
       "      <th>data__size</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>vect__max_df</th>\n",
       "      <th>clf__penalty</th>\n",
       "      <th>clf__C</th>\n",
       "      <th>cv__fold</th>\n",
       "      <th>cv__scoring</th>\n",
       "      <th>cv__score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.133969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.498315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.666026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.741688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.120475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.502656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.672290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.742170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.759995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOD</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.762888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Underflow</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.993151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Underflow</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.806669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overflow</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Overflow</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CallDepth</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CallDepth</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TimeDep</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TimeDep</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.002037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Reentracy</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Reentracy</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AssertFail</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.543306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AssertFail</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.570990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TxOrigin</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TxOrigin</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CheckEffects</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.606509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CheckEffects</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.676297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>InlineAssembly</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>InlineAssembly</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.009535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BlockTimestamp</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.810333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BlockTimestamp</td>\n",
       "      <td>14383</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.756537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.721569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.716665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.724508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.692157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.726471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.720588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.834313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.842157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.746077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.777449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.838235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.842156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.738234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.769606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.854902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.860785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.733331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.765684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.861765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.726468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.760783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.809805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.828431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.695097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.719606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.812745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.833332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.695097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>SelfDestruct</td>\n",
       "      <td>14383</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.722548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>554 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        data__label  data__size vect__ngram_range  vect__max_df clf__penalty  \\\n",
       "0               TOD       14383            (1, 1)           0.5           l1   \n",
       "1               TOD       14383            (2, 2)           0.5           l1   \n",
       "2               TOD       14383            (3, 3)           0.5           l1   \n",
       "3               TOD       14383            (4, 4)           0.5           l1   \n",
       "4               TOD       14383            (1, 1)           0.7           l1   \n",
       "5               TOD       14383            (2, 2)           0.7           l1   \n",
       "6               TOD       14383            (3, 3)           0.7           l1   \n",
       "7               TOD       14383            (4, 4)           0.7           l1   \n",
       "8               TOD       14383            (5, 5)           0.5           l1   \n",
       "9               TOD       14383            (5, 5)           0.7           l1   \n",
       "10        Underflow       14383            (1, 1)           0.5           l1   \n",
       "11        Underflow       14383            (1, 1)           0.7           l1   \n",
       "12         Overflow       14383            (1, 1)           0.5           l1   \n",
       "13         Overflow       14383            (1, 1)           0.7           l1   \n",
       "14        CallDepth       14383            (1, 1)           0.5           l1   \n",
       "15        CallDepth       14383            (1, 1)           0.7           l1   \n",
       "16          TimeDep       14383            (1, 1)           0.5           l1   \n",
       "17          TimeDep       14383            (1, 1)           0.7           l1   \n",
       "18        Reentracy       14383            (1, 1)           0.5           l1   \n",
       "19        Reentracy       14383            (1, 1)           0.7           l1   \n",
       "20       AssertFail       14383            (1, 1)           0.5           l1   \n",
       "21       AssertFail       14383            (1, 1)           0.7           l1   \n",
       "22         TxOrigin       14383            (1, 1)           0.5           l1   \n",
       "23         TxOrigin       14383            (1, 1)           0.7           l1   \n",
       "24     CheckEffects       14383            (1, 1)           0.5           l1   \n",
       "25     CheckEffects       14383            (1, 1)           0.7           l1   \n",
       "26   InlineAssembly       14383            (1, 1)           0.5           l1   \n",
       "27   InlineAssembly       14383            (1, 1)           0.7           l1   \n",
       "28   BlockTimestamp       14383            (1, 1)           0.5           l1   \n",
       "29   BlockTimestamp       14383            (1, 1)           0.7           l1   \n",
       "..              ...         ...               ...           ...          ...   \n",
       "524    SelfDestruct       14383            (2, 2)           0.5           l2   \n",
       "525    SelfDestruct       14383            (2, 2)           0.5           l2   \n",
       "526    SelfDestruct       14383            (2, 2)           0.7           l1   \n",
       "527    SelfDestruct       14383            (2, 2)           0.7           l1   \n",
       "528    SelfDestruct       14383            (2, 2)           0.7           l2   \n",
       "529    SelfDestruct       14383            (2, 2)           0.7           l2   \n",
       "530    SelfDestruct       14383            (3, 3)           0.5           l1   \n",
       "531    SelfDestruct       14383            (3, 3)           0.5           l1   \n",
       "532    SelfDestruct       14383            (3, 3)           0.5           l2   \n",
       "533    SelfDestruct       14383            (3, 3)           0.5           l2   \n",
       "534    SelfDestruct       14383            (3, 3)           0.7           l1   \n",
       "535    SelfDestruct       14383            (3, 3)           0.7           l1   \n",
       "536    SelfDestruct       14383            (3, 3)           0.7           l2   \n",
       "537    SelfDestruct       14383            (3, 3)           0.7           l2   \n",
       "538    SelfDestruct       14383            (4, 4)           0.5           l1   \n",
       "539    SelfDestruct       14383            (4, 4)           0.5           l1   \n",
       "540    SelfDestruct       14383            (4, 4)           0.5           l2   \n",
       "541    SelfDestruct       14383            (4, 4)           0.5           l2   \n",
       "542    SelfDestruct       14383            (4, 4)           0.7           l1   \n",
       "543    SelfDestruct       14383            (4, 4)           0.7           l1   \n",
       "544    SelfDestruct       14383            (4, 4)           0.7           l2   \n",
       "545    SelfDestruct       14383            (4, 4)           0.7           l2   \n",
       "546    SelfDestruct       14383            (5, 5)           0.5           l1   \n",
       "547    SelfDestruct       14383            (5, 5)           0.5           l1   \n",
       "548    SelfDestruct       14383            (5, 5)           0.5           l2   \n",
       "549    SelfDestruct       14383            (5, 5)           0.5           l2   \n",
       "550    SelfDestruct       14383            (5, 5)           0.7           l1   \n",
       "551    SelfDestruct       14383            (5, 5)           0.7           l1   \n",
       "552    SelfDestruct       14383            (5, 5)           0.7           l2   \n",
       "553    SelfDestruct       14383            (5, 5)           0.7           l2   \n",
       "\n",
       "     clf__C  cv__fold cv__scoring  cv__score  \n",
       "0      30.0         2      recall   0.133969  \n",
       "1      30.0         2      recall   0.498315  \n",
       "2      30.0         2      recall   0.666026  \n",
       "3      30.0         2      recall   0.741688  \n",
       "4      30.0         2      recall   0.120475  \n",
       "5      30.0         2      recall   0.502656  \n",
       "6      30.0         2      recall   0.672290  \n",
       "7      30.0         2      recall   0.742170  \n",
       "8      30.0         2      recall   0.759995  \n",
       "9      30.0         2      recall   0.762888  \n",
       "10     30.0         2      recall   0.993151  \n",
       "11     30.0         2      recall   0.806669  \n",
       "12     30.0         2      recall   1.000000  \n",
       "13     30.0         2      recall   1.000000  \n",
       "14     30.0         2      recall   0.000000  \n",
       "15     30.0         2      recall   0.000000  \n",
       "16     30.0         2      recall   0.000000  \n",
       "17     30.0         2      recall   0.002037  \n",
       "18     30.0         2      recall   0.000000  \n",
       "19     30.0         2      recall   0.000000  \n",
       "20     30.0         2      recall   0.543306  \n",
       "21     30.0         2      recall   0.570990  \n",
       "22     30.0         2      recall   0.000000  \n",
       "23     30.0         2      recall   0.000000  \n",
       "24     30.0         2      recall   0.606509  \n",
       "25     30.0         2      recall   0.676297  \n",
       "26     30.0         2      recall   0.000000  \n",
       "27     30.0         2      recall   0.009535  \n",
       "28     30.0         2      recall   0.810333  \n",
       "29     30.0         2      recall   0.756537  \n",
       "..      ...       ...         ...        ...  \n",
       "524    30.0         5      recall   0.721569  \n",
       "525   100.0         5      recall   0.716665  \n",
       "526    30.0         5      recall   0.724508  \n",
       "527   100.0         5      recall   0.692157  \n",
       "528    30.0         5      recall   0.726471  \n",
       "529   100.0         5      recall   0.720588  \n",
       "530    30.0         5      recall   0.834313  \n",
       "531   100.0         5      recall   0.842157  \n",
       "532    30.0         5      recall   0.746077  \n",
       "533   100.0         5      recall   0.777449  \n",
       "534    30.0         5      recall   0.838235  \n",
       "535   100.0         5      recall   0.842156  \n",
       "536    30.0         5      recall   0.738234  \n",
       "537   100.0         5      recall   0.769606  \n",
       "538    30.0         5      recall   0.854902  \n",
       "539   100.0         5      recall   0.860785  \n",
       "540    30.0         5      recall   0.733331  \n",
       "541   100.0         5      recall   0.765684  \n",
       "542    30.0         5      recall   0.850000  \n",
       "543   100.0         5      recall   0.861765  \n",
       "544    30.0         5      recall   0.726468  \n",
       "545   100.0         5      recall   0.760783  \n",
       "546    30.0         5      recall   0.809805  \n",
       "547   100.0         5      recall   0.828431  \n",
       "548    30.0         5      recall   0.695097  \n",
       "549   100.0         5      recall   0.719606  \n",
       "550    30.0         5      recall   0.812745  \n",
       "551   100.0         5      recall   0.833332  \n",
       "552    30.0         5      recall   0.695097  \n",
       "553   100.0         5      recall   0.722548  \n",
       "\n",
       "[554 rows x 9 columns]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class HyperparamKeeper:\n",
    "    \n",
    "    @property\n",
    "    def df(self):\n",
    "        self.__check_dirty()\n",
    "        return self.__params\n",
    "    \n",
    "    def __init__(self, filename, cols, convs=None):\n",
    "        self.__fname = filename\n",
    "        self.__params = pd.read_csv(self.__fname, index_col=0, converters=convs) if os.path.exists(self.__fname) else\\\n",
    "                        pd.DataFrame([], columns=cols)\n",
    "        self.__dirty = False\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.__params)\n",
    "    \n",
    "    def __check_dirty(self):\n",
    "        if self.__dirty:\n",
    "            self.__params.drop_duplicates(inplace=True)\n",
    "            self.__dirty = False\n",
    "    \n",
    "    def __check_pm_name(self, pm, target=None):\n",
    "        if target is None:\n",
    "            target = self.__params.columns\n",
    "        \n",
    "        if len(pm) != len(target):\n",
    "            return False\n",
    "        \n",
    "        for name in pm:\n",
    "            if name not in target:\n",
    "                logging.warning(\"The parameter name '%s' is not allowed\" % name)\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def __assert_pm_name(self, pm, target=None):\n",
    "        if not self.__check_pm_name(pm, target):\n",
    "            raise Exception('Not matched param columns')\n",
    "            \n",
    "    def __cond(self, pm):\n",
    "        for i, (p, v) in enumerate(pm.items()):\n",
    "            if i == 0:\n",
    "                cond = (self.__params[p] == v)\n",
    "            else:\n",
    "                cond &= (self.__params[p] == v)\n",
    "        return cond\n",
    "        \n",
    "    def __dup_params(self, pm):\n",
    "        self.__assert_pm_name(pm, self.__params.columns[:-1])\n",
    "        return self.__params[self.__cond(pm)]\n",
    "\n",
    "    \n",
    "    def is_dup(self, pm):\n",
    "        return not self.__dup_params(pm).empty\n",
    "\n",
    "    \n",
    "    def add(self, pm, ifdup='update'):\n",
    "        self.__assert_pm_name(pm)\n",
    "        self.__params.loc[len(self.__params)] = pm\n",
    "        self.__dirty = True\n",
    "\n",
    "    def save(self):\n",
    "        self.__check_dirty()\n",
    "        self.__params.to_csv(self.__fname)\n",
    "    \n",
    "    # put new item and return (new) dict\n",
    "    @staticmethod\n",
    "    def __put(d, k, v, inplace=False):\n",
    "        if not inplace:\n",
    "            d = d.copy()\n",
    "        d[k] = v\n",
    "        return d\n",
    "\n",
    "    # return the list of pm generated form meta[idx:]\n",
    "    # @pm is a dict of paramter/value\n",
    "    @classmethod\n",
    "    def __gen(cls, meta, idx):\n",
    "        if idx >= len(meta):\n",
    "            return [{}]  # empty pm\n",
    "\n",
    "        p, vals = meta[idx]\n",
    "\n",
    "        # 'inplace' is not necessary, just for dict reuse\n",
    "        return [ cls.__put(pm, p, v, inplace=(i==0)) \\\n",
    "                    for pm in cls.__gen(meta, idx + 1) \\\n",
    "                        for i, v in enumerate(vals) ]\n",
    "\n",
    "    @classmethod    \n",
    "    def __split_pm_temp(cls, pm_temp):\n",
    "        meta = {}\n",
    "        rec = {}\n",
    "        for p, val in pm_temp.items():\n",
    "            if isinstance(val, list):\n",
    "                meta[p] = val\n",
    "            else:\n",
    "                rec[p] = val\n",
    "        return meta, rec\n",
    "   \n",
    "       \n",
    "    \n",
    "    # @pm_rec: not 'score' and not 'meta'\n",
    "    # return best score and its meta param\n",
    "    def best_param(self, pm_rec):\n",
    "        score_col = self.__params.columns[-1] #last column is core column\n",
    "        calidates = self.__params[self.__cond(pm_rec)][score_col]\n",
    "        if calidates.empty:\n",
    "            return None, None\n",
    "        best = calidates.idxmax()\n",
    "        best_pm = dict(self.__params.iloc[best].items())\n",
    "        \n",
    "        score = best_pm.pop(score_col)\n",
    "        for p in pm_rec:\n",
    "            del best_pm[p]\n",
    "            \n",
    "        return best_pm, score\n",
    "\n",
    "    # @pm_temp: parameter template: contain 'meta' (list) and 'rec' (normal), without 'score' column\n",
    "    # flaten params and skim the duplicatd params, according to @pm_temp\n",
    "    def gen_params(self, pm_temp, by='nodup'):\n",
    " \n",
    "        # extract meta parameter from template\n",
    "        meta, rec = self.__split_pm_temp(pm_temp)\n",
    "                \n",
    "        def listify(pm):\n",
    "            for p in meta:\n",
    "                v = pm[p]\n",
    "                pm[p] = [v]\n",
    "            return pm\n",
    "        \n",
    "        metas = []\n",
    "        for m in self.__gen(list(meta.items()), 0):            \n",
    "            if not self.is_dup({**m, **rec}):\n",
    "                metas.append(listify(m))\n",
    "                \n",
    "        return metas\n",
    "\n",
    "        '''\n",
    "        # a trivial version of __gen(meta,0) is like below, if len(meta) is fixed to 4:\n",
    "        p1, p2, p3, p4 = meta                \n",
    "        for v1 in pm_meta[p1]:\n",
    "            for v2 in pm_meta[p2]:\n",
    "                for v3 in pm_meta[p3]:\n",
    "                    for v4 in pm_meta[p4]:\n",
    "                        pm = {p1: v1, p2: v2, p3: v3, p4: v4}\n",
    "        '''\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "            format=\"%(asctime)s.%(msecs)03d [%(levelname)s] [%(module)s] %(message)s\", datefmt=\"%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "cols = ('data__label', 'data__size', 'vect__ngram_range', 'vect__max_df', 'clf__penalty', 'clf__C', 'cv__fold', 'cv__scoring', 'cv__score')\n",
    "hyparams = HyperparamKeeper('.params', cols)\n",
    "hyparams.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.5],\n",
       "  'vect__ngram_range': [(1, 1)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.5],\n",
       "  'vect__ngram_range': [(2, 2)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.5],\n",
       "  'vect__ngram_range': [(3, 3)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.5],\n",
       "  'vect__ngram_range': [(4, 4)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.5],\n",
       "  'vect__ngram_range': [(5, 5)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.5],\n",
       "  'vect__ngram_range': [(99, 99)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.7],\n",
       "  'vect__ngram_range': [(1, 1)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.7],\n",
       "  'vect__ngram_range': [(2, 2)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.7],\n",
       "  'vect__ngram_range': [(3, 3)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.7],\n",
       "  'vect__ngram_range': [(4, 4)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.7],\n",
       "  'vect__ngram_range': [(5, 5)]},\n",
       " {'clf__C': [30.0],\n",
       "  'clf__penalty': ['l1'],\n",
       "  'vect__max_df': [0.7],\n",
       "  'vect__ngram_range': [(99, 99)]}]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_meta = {\n",
    "    'clf__C': [30.0],\n",
    "    'clf__penalty': ['l1'],\n",
    "    'vect__max_df': [0.5, 0.7],\n",
    "    'vect__ngram_range': [(1,1), (2,2), (3, 3), (4,4), (5,5), (99,99)],\n",
    "}\n",
    "pm_rec = {\n",
    "    'data__label': 'TOD',\n",
    "    'data__size': 14383,\n",
    "    'cv__fold': 2,\n",
    "    'cv__scoring': 'recall',\n",
    "    }\n",
    "pm_temp = {**pm_meta, **pm_rec}\n",
    "\n",
    "hyparams.gen_params(pm_temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best for  Underflow\n",
      "  score:  0.9944989837551056\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 30.0, 'vect__ngram_range': '(1, 1)', 'vect__max_df': 0.5}\n",
      "best for  Overflow\n",
      "  score:  1.0\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 30.0, 'vect__ngram_range': '(1, 1)', 'vect__max_df': 0.5}\n",
      "best for  Multisig\n",
      "  score:  None\n",
      "  param:  None\n",
      "best for  CallDepth\n",
      "  score:  0.757933600386496\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 100.0, 'vect__ngram_range': '(4, 4)', 'vect__max_df': 0.7}\n",
      "best for  TOD\n",
      "  score:  0.8038586383355852\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 100.0, 'vect__ngram_range': '(5, 5)', 'vect__max_df': 0.5}\n",
      "best for  TimeDep\n",
      "  score:  0.7138982081697317\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 100.0, 'vect__ngram_range': '(5, 5)', 'vect__max_df': 0.5}\n",
      "best for  Reentracy\n",
      "  score:  0.8085548890604524\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 100.0, 'vect__ngram_range': '(5, 5)', 'vect__max_df': 0.5}\n",
      "best for  AssertFail\n",
      "  score:  0.9234255886718212\n",
      "  param:  {'clf__penalty': 'l2', 'clf__C': 100.0, 'vect__ngram_range': '(5, 5)', 'vect__max_df': 0.5}\n",
      "best for  TxOrigin\n",
      "  score:  0.8786729704048762\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 100.0, 'vect__ngram_range': '(3, 3)', 'vect__max_df': 0.5}\n",
      "best for  CheckEffects\n",
      "  score:  0.9316048220116108\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 30.0, 'vect__ngram_range': '(5, 5)', 'vect__max_df': 0.5}\n",
      "best for  InlineAssembly\n",
      "  score:  0.8855971979147365\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 100.0, 'vect__ngram_range': '(5, 5)', 'vect__max_df': 0.5}\n",
      "best for  BlockTimestamp\n",
      "  score:  0.9530086179547292\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 100.0, 'vect__ngram_range': '(4, 4)', 'vect__max_df': 0.7}\n",
      "best for  LowlevelCalls\n",
      "  score:  0.9235905097334336\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 100.0, 'vect__ngram_range': '(5, 5)', 'vect__max_df': 0.7}\n",
      "best for  BlockHash\n",
      "  score:  None\n",
      "  param:  None\n",
      "best for  SelfDestruct\n",
      "  score:  0.8617652511884264\n",
      "  param:  {'clf__penalty': 'l1', 'clf__C': 100.0, 'vect__ngram_range': '(4, 4)', 'vect__max_df': 0.7}\n"
     ]
    }
   ],
   "source": [
    "pm_rec = {\n",
    "    #'data__label': 'TOD',\n",
    "    'data__size': 14383,\n",
    "    'cv__fold': 5,\n",
    "    'cv__scoring': 'recall',\n",
    "    }\n",
    "for vul in ALL_VULS:\n",
    "    pm_rec['data__label'] = vul\n",
    "    param, score = hyparams.best_param(pm_rec)\n",
    "    print('best for ', vul)\n",
    "    print('  score: ', score)\n",
    "    print('  param: ', param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Velidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pformat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# the CV who remembers its historic tained hyperparameters\n",
    "# TODO using Template Desing Pattern to split underlying cv and logic\n",
    "class MemoCV:\n",
    "    @property\n",
    "    def scoring(self):\n",
    "        return self.__scoring\n",
    "\n",
    "    @property\n",
    "    def fold(self):\n",
    "        return self.__fold\n",
    "\n",
    "    def __init__(self, file_params, scoring, fold):\n",
    "        cols = ('data__label', 'data__size', 'vect__ngram_range', 'vect__max_df', 'clf__penalty', 'clf__C', 'cv__fold', 'cv__scoring', 'cv__score')    \n",
    "        self.__hyparams = HyperparamKeeper(file_params, cols, {\"vect__ngram_range\": eval})\n",
    "\n",
    "        self.__scoring = scoring\n",
    "        self.__fold = fold\n",
    "\n",
    "    @classmethod\n",
    "    def __get_pipe_model(cls, pipe, name):\n",
    "        for n, m in pipe.steps:\n",
    "            if n == name:\n",
    "                return m\n",
    "        return None\n",
    "\n",
    "    @classmethod\n",
    "    def __extract_pm(cls, pipe):\n",
    "        if pipe is None:\n",
    "            return None\n",
    "        \n",
    "        vect = cls.__get_pipe_model(pipe, 'vect')\n",
    "        clf = cls.__get_pipe_model(pipe, 'clf')\n",
    "        \n",
    "        return {\n",
    "            'clf__C': clf.C,\n",
    "            'clf__penalty': clf.penalty,\n",
    "            'vect__max_df': vect.max_df,\n",
    "            'vect__ngram_range': vect.ngram_range\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def __import_pm(cls, pipe, pm, vect=None, clf=None):\n",
    "        if vect is None:\n",
    "            vect = cls.__get_pipe_model(pipe, 'vect')\n",
    "        if clf is None:\n",
    "            clf = cls.__get_pipe_model(pipe, 'clf')\n",
    "        \n",
    "        vect.ngram_range = pm['vect__ngram_range']\n",
    "        vect.max_df = pm['vect__max_df']\n",
    "        clf.C = pm['clf__C']\n",
    "        clf.penalty = pm['clf__penalty']\n",
    "        \n",
    "    @staticmethod\n",
    "    def tokenizer(text):\n",
    "        return text.split()\n",
    "\n",
    "    @classmethod\n",
    "    def __get_raw_model(cls, init_pm=None):\n",
    "        vect = TfidfVectorizer(strip_accents=None,\n",
    "                lowercase=False,\n",
    "                preprocessor=None,\n",
    "                stop_words=None, #const.STOP_WORDS,\n",
    "                tokenizer=cls.tokenizer)\n",
    "\n",
    "        clf = LogisticRegression(random_state=0)\n",
    "        \n",
    "        if init_pm is not None:\n",
    "            cls.__import_pm(None, init_pm, vect, clf)\n",
    "            \n",
    "        return Pipeline([('vect', vect),\n",
    "                         ('std', StandardScaler(with_mean=False)),\n",
    "                         ('clf', clf)])\n",
    "\n",
    "        \n",
    "    # @labelname is \n",
    "    def fit(self, X, y, pm_meta, label):\n",
    "        # get untrained hyperparameters\n",
    "        pm_rec = {\n",
    "         'cv__fold': self.__fold,\n",
    "         'cv__scoring': self.__scoring,\n",
    "         'data__size': len(X),\n",
    "         'data__label': label\n",
    "        }\n",
    "\n",
    "        pm_temp = { **pm_meta, **pm_rec}        \n",
    "        params = self.__hyparams.gen_params(pm_temp)\n",
    "\n",
    "        if params:\n",
    "            model = self.__get_raw_model()\n",
    "            cv = GridSearchCV(model, params,\n",
    "                scoring=self.__scoring,\n",
    "                cv=self.__fold,\n",
    "                verbose=1,\n",
    "                n_jobs=-1,\n",
    "                return_train_score=True)\n",
    "\n",
    "            cv.fit(X, y)          \n",
    "            \n",
    "\n",
    "            #save hyperparameters \n",
    "            for score, std, pm in zip(cv.cv_results_['mean_test_score'], cv.cv_results_['std_test_score'], cv.cv_results_['params']):\n",
    "                logging.info('score: %f, std: %f' % (score, std))\n",
    "                pm = {**pm, **pm_rec}\n",
    "                pm['cv__score'] = score                \n",
    "                self.__hyparams.add(pm)\n",
    "            self.__hyparams.save()\n",
    "         \n",
    "            # trained model\n",
    "            cv_model = cv.best_estimator_\n",
    "        else:\n",
    "            cv_model = None\n",
    "            logging.debug('All possbiles hyperparameters are trained: \\n%s' % pformat(pm_temp))\n",
    "        \n",
    "        # get best params from @pm_temp    \n",
    "        best_pm, best_score = self.__hyparams.best_param(pm_rec)\n",
    "        logging.info('[MemoCV] CV(%s,%d), Best Score: %f, Best parameter: \\n%s' % \n",
    "                     (self.__scoring, self.__fold, best_score, pformat(best_pm)))\n",
    "       \n",
    "        # return the model from best params\n",
    "        if self.__extract_pm(cv_model) == best_pm: # optimize for the lucky case\n",
    "            return cv_model\n",
    "        else:\n",
    "            logging.info('[MemoCV] Instaniate model from the best param')\n",
    "            model = self.__get_raw_model(best_pm)\n",
    "            model.fit(X, y)\n",
    "            return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train(X_train, y_train, vulname):\n",
    "    logging.info('[Train] Traiing...')\n",
    "\n",
    "    # data\n",
    "    #X_train, y_train, X_test, y_test = data_sets\n",
    "\n",
    "    # train\n",
    "    pm_meta = {\n",
    "            'clf__C': [30.0, 100.0],\n",
    "            'clf__penalty': ['l1', 'l2'],\n",
    "            'vect__max_df': [0.5, 0.7],\n",
    "            'vect__ngram_range': [(1,1),(2,2),(3,3),(4,4),(5,5)]}\n",
    "    #'vect__stop_words': [stop, None],\n",
    "    #'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "    #'vect__use_idf':[False],\n",
    "    #'vect__norm':[None],\n",
    "    cv = MemoCV('.params', 'f1', 5)\n",
    "    model = cv.fit(X_train, y_train, pm_meta, vulname)\n",
    "\n",
    "    #logging.info('[Train] Test %s: %.3f' % (cv.scoring, model.score(X_test, y_test)))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inflence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8588281  1.02663702 1.25686231]]\n",
      "[[0.78973913 3.54183066 0.61152417]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x1 = np.random.randn(100)\n",
    "x2 = 4*np.random.randn(100)\n",
    "x3 = 0.5*np.random.randn(100)\n",
    "y = (3 + x1 + x2 + x3 + 0.2*np.random.randn()) > 0\n",
    "X = np.column_stack([x1, x2, x3])\n",
    "\n",
    "m = LogisticRegression()\n",
    "m.fit(X, y)\n",
    "\n",
    "# The estimated coefficients will all be around 1:\n",
    "print(m.coef_)\n",
    "\n",
    "# Those values, however, will show that the second parameter\n",
    "# is more influential\n",
    "print(np.std(X, 0)*m.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_influence(model, X):\n",
    "    vect = model.steps[0][1]\n",
    "    clf = model.steps[-1][1]\n",
    "    \n",
    "    X_ft = vect.transform(X)\n",
    "    #X_ft_std = [np.std(X_ft.getcol(i).toarray()) \\\n",
    "    #           for i in range(X_ft.shape[1]) ]\n",
    "    X_ft_std = np.ones(X_ft.shape[1])\n",
    "\n",
    "    df = pd.DataFrame({'feature': vect.get_feature_names(),\n",
    "                   'ft_std': X_ft_std,\n",
    "                   'coef': clf.coef_[0]\n",
    "                  },\n",
    "                  columns=['feature', 'ft_std', 'coef'])\n",
    "\n",
    "\n",
    "    df['influence'] = df['coef'] * df['ft_std']\n",
    "    df.sort_values(by='influence', ascending=False, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>ft_std</th>\n",
       "      <th>coef</th>\n",
       "      <th>influence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74895</th>\n",
       "      <td>SUB ADD ADD SHA3 CALLER</td>\n",
       "      <td>0.049506</td>\n",
       "      <td>26.758043</td>\n",
       "      <td>1.324685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12721</th>\n",
       "      <td>ADDRESS BALANCE SUB CALL REVERT</td>\n",
       "      <td>0.022196</td>\n",
       "      <td>39.836806</td>\n",
       "      <td>0.884213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45521</th>\n",
       "      <td>REVERT ADDRESS BALANCE SUB CALL</td>\n",
       "      <td>0.017675</td>\n",
       "      <td>44.851419</td>\n",
       "      <td>0.792757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>ADD SHA3 CALLER SUB CALL</td>\n",
       "      <td>0.016163</td>\n",
       "      <td>37.974865</td>\n",
       "      <td>0.613797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53930</th>\n",
       "      <td>REVERT SUB CALLER REVERT SELFDESTRUCT</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>75.409057</td>\n",
       "      <td>0.577609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature    ft_std       coef  influence\n",
       "74895                SUB ADD ADD SHA3 CALLER  0.049506  26.758043   1.324685\n",
       "12721        ADDRESS BALANCE SUB CALL REVERT  0.022196  39.836806   0.884213\n",
       "45521        REVERT ADDRESS BALANCE SUB CALL  0.017675  44.851419   0.792757\n",
       "6222                ADD SHA3 CALLER SUB CALL  0.016163  37.974865   0.613797\n",
       "53930  REVERT SUB CALLER REVERT SELFDESTRUCT  0.007660  75.409057   0.577609"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = calc_influence(model, X_train)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "    \n",
    "def evaluate(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    total = len(X)\n",
    "    accu = accuracy_score(y, y_pred)\n",
    "    [p], [r], [f], [s] = precision_recall_fscore_support(y, y_pred, labels=[1])\n",
    "    s /= total\n",
    "    score = total, s, accu, p, r, f\n",
    "    logging.info('[EVAL]size %d, support %.3f, accuracy %.3f, precision %.3f, recall %.3f, fscore %.3f' % score)\n",
    "    \n",
    "    #score_s = pd.Series(score, index=['Size', 'Support', 'Accuracy', 'Precision', 'Recall', 'F1'])    \n",
    "    return score\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:32:23.797 [INFO] [<ipython-input-546-62ed976c03d5>] [EVAL]size 3596, support 0.891, accuracy 0.891, precision 0.891, recall 1.000, fscore 0.942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3596,\n",
       " 0.8907119021134594,\n",
       " 0.8907119021134594,\n",
       " 0.8907119021134594,\n",
       " 1.0,\n",
       " 0.9421973819679365)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = evaluate(model, X_test, y_test)\n",
    "score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:23:32.303 [INFO] [<ipython-input-656-cee08fb451f6>] [BlockTimestamp] Training ===================\n",
      "15:23:32.344 [INFO] [<ipython-input-601-3bae02751801>] [Train] Traiing...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Not matched param columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-656-cee08fb451f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[%s] Training ==================='\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minfluence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_influence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-601-3bae02751801>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, y_train, vulname)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#'vect__norm':[None],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMemoCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpm_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvulname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#logging.info('[Train] Test %s: %.3f' % (cv.scoring, model.score(X_test, y_test)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-599-919d835aaec7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, pm_meta, label)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mpm_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpm_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpm_rec\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__hyparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-458-5a5c5cd88b39>\u001b[0m in \u001b[0;36mgen_params\u001b[0;34m(self, pm_temp, by)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mmetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0mmetas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-458-5a5c5cd88b39>\u001b[0m in \u001b[0;36mis_dup\u001b[0;34m(self, pm)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_dup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dup_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-458-5a5c5cd88b39>\u001b[0m in \u001b[0;36m__dup_params\u001b[0;34m(self, pm)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dup_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__assert_pm_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-458-5a5c5cd88b39>\u001b[0m in \u001b[0;36m__assert_pm_name\u001b[0;34m(self, pm, target)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__assert_pm_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__check_pm_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not matched param columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Not matched param columns"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({}, columns=['vul',\n",
    "        'train_size', 'train_support', 'train_accuracy', 'train_precision', 'train_recall', 'train_f1',\n",
    "        'test_size', 'test_support', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1',\n",
    "        'top_ft_1', 'top_inf_1', 'top_ft_2', 'top_inf_2','top_ft_3', 'top_inf_3'])\n",
    "\n",
    "for vul in ['BlockTimestamp']:#ALL_VULS:\n",
    "    if (data[vul] == 1).sum() < 2:    #no enough sample to be grouped and train\n",
    "        #scores.append((zero,zero))\n",
    "        continue\n",
    "\n",
    "    logging.info('[%s] Training ===================' % vul)\n",
    "    X_train, y_train, X_test, y_test = splitData(data, vul)\n",
    "    model = train(X_train, y_train, vul)\n",
    "    \n",
    "    influence = calc_influence(model, X_train)\n",
    "    top3_inf_fts = influence[['feature', 'influence']].head(n=3).values.reshape(6)\n",
    "    logging.info('Influence:\\n%s\\n...\\n%s' % (influence.head(), influence.tail()))\n",
    "    \n",
    "    score_train = evaluate(model, X_train, y_train)\n",
    "    score_test = evaluate(model, X_test, y_test)\n",
    "    \n",
    "    results.loc[len(results)] = [vul, *score_train, *score_test, *top3_inf_fts]\n",
    "    \n",
    "\n",
    "\n",
    "results.set_index('vul', inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MemoCV at 0x7f6a4fc9e9b0>"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1 entries, Overflow to Overflow\n",
      "Data columns (total 18 columns):\n",
      "train_size         1 non-null float64\n",
      "train_support      1 non-null float64\n",
      "train_accuracy     1 non-null float64\n",
      "train_precision    1 non-null float64\n",
      "train_recall       1 non-null float64\n",
      "train_f1           1 non-null float64\n",
      "test_size          1 non-null float64\n",
      "test_support       1 non-null float64\n",
      "test_accuracy      1 non-null float64\n",
      "test_precision     1 non-null float64\n",
      "test_recall        1 non-null float64\n",
      "test_f1            1 non-null float64\n",
      "top_ft_1           1 non-null object\n",
      "top_inf_1          1 non-null float64\n",
      "top_ft_2           1 non-null object\n",
      "top_inf_2          1 non-null float64\n",
      "top_ft_3           1 non-null object\n",
      "top_inf_3          1 non-null float64\n",
      "dtypes: float64(15), object(3)\n",
      "memory usage: 152.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 302,   91],\n",
       "       [  63, 3140]])"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_name', 'a', 'b']"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a  = {'b': 1, 'a': 2}\n",
    "title = sorted(a.keys())\n",
    "['task_name', *title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__ngram_range': <function eval>}"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_grid = {\n",
    "         'clf__C': [30.0],\n",
    "         'clf__penalty': ['l1'],\n",
    "         'vect__max_df': [0.5, 0.7],\n",
    "         'vect__ngram_range': [(1,1), (2,2), (3, 3), (4,4), (5,5), (99,99)],\n",
    "         }\n",
    "convs = {p:eval for p, v in pm_grid.items() if isinstance(v[0], tuple)}\n",
    "convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(strip_accents=None,\n",
    "                lowercase=False,\n",
    "                preprocessor=None,\n",
    "                stop_words=None, #const.STOP_WORDS,\n",
    "                tokenizer=MemoCV.tokenizer,\n",
    "                ngram_range=(1,1),\n",
    "                max_df=0.7)\n",
    "\n",
    "\n",
    "data_std = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('std', StandardScaler(with_mean=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = data_std.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature', 'ft_std', 'coef']"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(df.columns)\n",
    "del a[-1]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Addr\n",
       "0x0000000000b3F879cb30FE243b4Dfee438691c04    CALLDATASIZE CALLDATALOAD REVERT CALLVALUE REV...\n",
       "0x000000002647e16d9bab9e46604d75591d289277    CALLDATASIZE CALLDATALOAD REVERT CALLVALUE REV...\n",
       "0x000000002bb43c83ece652d161ad0fa862129a2c    CALLDATASIZE CALLDATALOAD REVERT CALLVALUE REV...\n",
       "0x000000005fbe2cc9b1b684ec445caf176042348e    CALLDATASIZE CALLDATALOAD REVERT CALLVALUE REV...\n",
       "0x0006157838d5a6b33ab66588a6a693a57c869999                                          REVERT SHA3\n",
       "Name: Opcodes, dtype: object"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head().iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BALANCE',\n",
       " 'BLOCKHASH',\n",
       " 'CALLCODE',\n",
       " 'CALLDATACOPY',\n",
       " 'CODECOPY',\n",
       " 'CODESIZE',\n",
       " 'COINBASE',\n",
       " 'CREATE',\n",
       " 'DELEGATECALL',\n",
       " 'DIFFICULTY',\n",
       " 'EXTCODECOPY',\n",
       " 'EXTCODESIZE',\n",
       " 'GAS',\n",
       " 'GASLIMIT',\n",
       " 'GASPRICE',\n",
       " 'NUMBER',\n",
       " 'ORIGIN',\n",
       " 'SELFDESTRUCT',\n",
       " 'TIMESTAMP']"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = X_std.toarray()\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 7\n",
      "2 5 8\n",
      "3 6 9\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "c = [7, 8, 9]\n",
    "\n",
    "for x1, x2, x3 in zip(a, b, c):\n",
    "    print(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, \"xxx_model.pkl\")\n",
    "# and later...\n",
    "xxx_model = joblib.load(\"xxx_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xxx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17979 entries, 0x0000000000b3F879cb30FE243b4Dfee438691c04 to 0xfffeee1655f36233fd58fdda74720b4eb85fddec\n",
      "Data columns (total 16 columns):\n",
      "Underflow         17979 non-null int64\n",
      "Overflow          17979 non-null int64\n",
      "Multisig          17979 non-null int64\n",
      "CallDepth         17979 non-null int64\n",
      "TOD               17979 non-null int64\n",
      "TimeDep           17979 non-null int64\n",
      "Reentracy         17979 non-null int64\n",
      "AssertFail        17979 non-null int64\n",
      "TxOrigin          17979 non-null int64\n",
      "CheckEffects      17979 non-null int64\n",
      "InlineAssembly    17979 non-null int64\n",
      "BlockTimestamp    17979 non-null int64\n",
      "LowlevelCalls     17979 non-null int64\n",
      "BlockHash         17979 non-null int64\n",
      "SelfDestruct      17979 non-null int64\n",
      "Opcodes           17979 non-null object\n",
      "dtypes: int64(15), object(1)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12100,  4651],\n",
       "       [    0,  1228]])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "time_dep = data['TimeDep']\n",
    "blk_ts = data['BlockTimestamp']\n",
    "confusion_matrix(time_dep, blk_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10728,  6696],\n",
       "       [   68,   487]])"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(data['Reentracy'], data['CheckEffects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd0VOXWx/HvDiT0XgQpglRBihJEAS8gRRAEsYFSpCiK2K4CglgRaYIIiiIiggVRegtFkF6kmkCAUEJJ6IEQCOnJfv+YUfNyIQxlMslkf9bKMnPmzJkfx2R2nlP2I6qKMcYYczU+ng5gjDEmY7NCYYwxJk1WKIwxxqTJCoUxxpg0WaEwxhiTJisUxhhj0uS2QiEik0XktIjsusrzIiLjROSAiASJyL3uymKMMebGuXNEMQVomcbzrYBKzq9ewNduzGKMMeYGua1QqOoa4Fwaq7QDflCHTUBBESnprjzGGGNuTHYPvncpICzV43DnshOXrygivXCMOsiTJ0+dqlWrpktAY4zJrFIUIqLjOR5+lOS4S5CSHKGqxW5kW54sFHKFZVfsJ6KqE4GJAP7+/rp161Z35jLGmEwrOUWZtS2M0cv24XMxngI7AiiTK5HAed8eudFtevKqp3CgTKrHpYHjHspijDGZ3tr9Z2j28Ry6PfsUBzctoVrJ/Mwf/xF/zZ14U9v15IhiPvCKiEwH6gFRqvo/h52MMcakbc+JCwwN2EPAjJ+IXDkZ0WS6Pt2er15tiI/PlQ7eXB+3FQoR+QVoDBQVkXDgA8AXQFUnAAHAI8ABIAbo7q4sxhjjjU5GxTF6WQi/rNhCxOIviD8aROV77mfOtKlUq1r5lr2P2wqFqj5zjecV6OOu9zfGGG8VHZ/EN6sP8u3aUOISU0iOOAIRoXw2bjxvvNIbkZsfRaTmyUNPxhhjrkNScgq/bAlj7PJ9HD+0j4RTB3mqYyf69x1AfnmDIkWKuOV9rVAYY0wGp6os33Oa4Yv3cODkeaI2/saFTTMoXrw4Y2YOJWfOnEAet72/FQpjjMnAAsPO80nAHjYfOkf88RAuLPuCmFOH6dy5M2PGjHEWCfeyQmGMMRlQ2LkYPl0awvxAx10DeZKiCP9lACVL3MZvCxfSunXrdMtihcIYYzKQqJhEvly5n6kbjpCQnAJRx3mxbUNeblyRPxrkomnTpuTPnz9dM1mhMMaYDCA+KZkfNx7hiz8OEBWbSEpcNAV2/kbwyjk0eGYVBXLdRfv27T2SzQqFMcZ4kKqyMOgEI5fuJexcLABlL+4mZNYYdp85Rb9+/ahbt65HM1qhMMYYD9l86ByfBOwhMOw8AJWK58V3w0QWz5pGjRo1WLRwPv7+/h5OaYXCGGPS3cEz0QxfvJffd58CoEgeP95qUZmn/cswKfceHqhVlbfffhs/Pz8PJ3WwQmGMMekkIjqescv3M23zUZJTlFy+2Xiqai42/zSC5HLPkL1eF1566SVPx/wfViiMMcbNYhOS+W5dKBNWhxIdn4SPQEf/UhQ+uoYhvd8lOTmZJ5943NMxr8oKhTHGuElyijJ7ezijl+3j5IU4AJpUKcYzVX35ZMDrrFmzhmbNmjFx4kTKly/v4bRXZ4XCGGPcYM2+MwwN2MPekxcBqH57fgY9chf1KxZl3rx5BAUFMXnyZLp163bLm/jdalYojDHmFvp7boi1+yMAuL1ATvo+XIXyEkHQ+kXUr/gc7dq1IzQ0lEKFCnk4rWusUBhjzC1wMS6R4Yv3Mm3zUVQhX47svNykIs/6l2TUiGF0GD6ckiVL0qFDB3LmzJlpigRYoTDGmJu2Zt8ZBs7eybHzsWT3ETo/cAevNa1ESNA2HrjvUfbs2UPXrl357LPP0qWJ361mhcIYY27QhbhEPlm4h1+3hgFQo1QBPn2qJlVL5OfYsWM0atSIEiVKEBAQQKtWrTyc9sZZoTDGmBuwMuQ078zeyYmoOPyy+fB6s0q8+J872b8vBErkp1SpUvz22280bdqUfPnyeTruTfHxdABjjMlMomIS6TsjkO7fb+FEVBy1yhRk0WsNebZ2EXq98DzVqlVj7dq1ADz22GOZvkiAjSiMMcZly3ef4p05Ozl9MR6/7D681bwyPRuWZ8H8ebz88sucOXOGgQMHeryJ361mhcIYY67hfEwCHy3YzZwdxwC4t2xBRj5Zi4rF89KjRw++//57ateuzaJFi7j33ns9nPbWs0JhjDFpWBp8kkFzdhERHU+O7D70e7gK3eqXI5uP4ya5+++/n0qVKtG3b198fX09nNY9rFAYY8wVnLuUwIfzg/+ZirRuuUKMfLIWPpciaNP6EZ599lm6du1Kr169PJzU/exktjHGXCZg5wlajFnN/MDj5PLNxgePVuOX5+sR8OsU7r77btatW0diYqKnY6YbG1EYY4xTRHQ8H8wLZtHOEwDcf2dhRjxRk7iIcJo0acy6deto0aIF33zzDeXKlfNs2HRkhcIYk+X9PR3pB/ODOXcpgdx+2RjYqiqd6t2Bj48wf30IwcHBTJkyha5du2b4Jn63mhUKY0yWdvpiHO/N3cXSYMdsc/UrFGHEEzWJOBLC1Kkr6d69O23btiU0NJSCBQt6OK1nWKEwxmRJqsq8v47z4YJgzsckkjdHdt555C7a1yzGxx9/zMiRIylVqhTPPPMMOXPmzLJFAqxQGGOyoNMX4nhnzi6W73GMIh6sVJThT9TkcPB27rmnBSEhIXTv3p3Ro0dnyiZ+t5oVCmNMlqGqzNp+jMELgrkQl0S+HNl5r001nvIvzfHjx2nSpAmlSpVi6dKltGjRwtNxMwwrFMaYLOFEVCzvzN7JypAzgGNK0qGP1yDy2CFEhFKlSjFr1iyaNGlC3rx5PZw2Y7H7KIwxXk1V+W1LGC0+W8PKkDPkz5mdUU/VYlTbCgx8vTfVq1dnzZo1ADz66KNWJK7ARhTGGK917HwsA2fvZM0+xyii2V3F+aR9Ddb9vojqrftw9uxZBg0axH333efhpBmbFQpjjNdRVX7ZHMbQgD1ExydRMLcvHz5anXa1b6d79+5MnTqVe++9lyVLllC7dm1Px83wrFAYY7xK2LkYBswOYv2BswA8XP02BrerTvF8ORER6tevz1133cVbb71F9uz2EegKt+4lEWkJjAWyAZNUdfhlz5cFpgIFnesMUNUAd2YyxninlBTl5z+PMGzxXmISkimU25fB7e6mer44Oj/Rls6dO/Pcc89liSZ+t5rbTmaLSDZgPNAKqAY8IyLVLlvtXeA3Vb0H6Ah85a48xhjvdfRsDM9O2sR784KJSUimdY2SLHm9IYdWz6RGjRps2rQJVfV0zEzLnSOK+4ADqhoKICLTgXbA7lTrKJDf+X0B4Lgb8xhjvExKivLDxsOMWBJCbGIyRfL48fFjd1M++3nat2rGxo0badWqFRMmTKBs2bKejptpubNQlALCUj0OB+pdts6HwDIReRXIAzS70oZEpBfQC7D/2cYYAA5FXOLtmUFsPnwOgEdr3c5HbatTOI8fCxZsJSQkhB9//JFOnTpluSZ+t5o776O40v+Zy8d+zwBTVLU08Ajwo4j8TyZVnaiq/qrqX6xYMTdENcZkFskpyqS1obQau4bNh89RNG8OvulSh26VU5j760+A436IQ4cO0blzZysSt4A7C0U4UCbV49L876GlnsBvAKq6EcgJFHVjJmNMJnbwTDRPTdjAkEV7iEtMof09pVjQuy4rf/ycevXq8fHHHxMXFwdA/vz5r7E14yp3HnraAlQSkfLAMRwnq5+9bJ2jQFNgiojchaNQnHFjJmNMJvT3KGL07/tISEqheL4cDG1fA7+IEBo9UJf9+/fTs2dPRo0aZU383MBthUJVk0TkFWApjktfJ6tqsIgMBraq6nzgLeBbEfkvjsNS3dQuTTDGpLL/1EX6zQzir7DzADxZpzTvta5GdORpytVqSpkyZVi+fDlNmzb1cFLv5db7KJz3RARctuz9VN/vBhq4M4MxJnNKSk7hmzWhjF2+n4TkFErkz8mwJ2pQNOEUBXL7UiB3KebMmUOTJk3IkyePp+N6NWsKaIzJcEJOXuTxrzfw6dIQEpJT6Fi3DL90rcbkIW9Rs2bNf5r4tWnTxopEOrD7140xGUZicgpfrzrIF3/sJzFZub1AToY9XoNTgauod28zIiMj+eCDD6hX7/Ir7Y07WaEwxmQIu49foN/MQIKPXwDg2XplGdiqKn169eTHH3/E39+fFStWUKNGDQ8nzXqsUBhjPCohKYXxKw8wfuUBklKU0oVyMfzxGjSoWBQRoVGjRtSsWZM33njDmvh5iO11Y4zH7DoWRd8Zgew9eRGArg/cwdOV/Xj9pY507tyZ7t2707NnTw+nNHYy2xiT7uKTkhm1NIR249ez9+RFyhbOzU896lL40HLq+d/Dli1b8PGxj6eMwkYUxph0FRh2nn4zA9l3KhoR6N6gHG3KJtOna1v+/PNPWrduzYQJEyhdurSnoxonKxTGmHQRl5jM2BX7+Wb1QVIUyhfNw8gna1K3XGEWLVrEwYMHmTZtGh07drT+TBmMFQpjjNttPxpJ/5lBHDjtGEU837A8jQpf4K/fZ1H3hRdo3bo1oaGh5MuXz9NRzRXYQUBjjNvEJSYzNGAPT369gQOno7mzWB5+eq4251dNpvGDDRg2bNg/TfysSGRcNqIwxrjF1sPn6D8ziNCIS/gIvNjoTur4Hue5No04ePAgL774IiNGjLAmfpmAFQpjzC0Vm5DMp0tD+H7DIVShUvG8fPpULYpKNOXLt+SOO+7gjz/+oEmTJp6OalxkhcIYc8v8GXqWt2cFcfhsDNl8hJca30njojHULlMQKMi8efNo3LgxuXPn9nRUcx3sHIUx5qbFJCTx4fxgOkzcxOGzMVS5LR+TO1Rhx9TB3Odfh9WrVwPwyCOPWJHIhGxEYYy5KRsORvD2rCDCzsWS3Ufo3bgCxU9v5clmTxAVFcVHH33EAw884OmY5ia4VChExA8oq6oH3JzHGJNJRMcnMXzxHn7adBSAu0rmZ9RTNRnWvw8///wz9erV47vvvqN69eoeTmpu1jULhYi0Bj4D/IDyIlIb+EBV27s7nDEmY1q33zGKOHY+Ft9swsuNKtDnoYr4Zc9GkyZNqFOnDq+99hrZsmXzdFRzC7gyohgM1ANWAqjqXyJS0a2pjDEZ0sW4RIYG7OGXzWEA3F0qP6/UycuIQS9RILwLPXr0sCZ+XsiVk9mJqnr+smU2r7UxWczqfWd4eMwaftkchl82H95sVoEHYzfRvml9duzYgZ+fn6cjGjdxZUSxR0SeBnxEpDzwOrDJvbGMMRlFVGwiQxbuZsa2cABqlS7AC3f78lG/LmzdupV27drx1Vdfcfvtt3s4qXEXV0YUrwB1gBRgNhCHo1gYY7zcH3tP0WLMamZsC8cvuw8DWlVlVu/6+MSc5ciRI0yfPp05c+ZYkfByrowoHlbVt4G3/14gIo/jKBrGGC8UFZPIRwuDmb39GAD3lC1Ip/IJnAtZQfZGvXjkkUcIDQ0lb968Hk5q0oMrI4p3r7Bs0K0OYozJGH7ffYpmY1Yze/sxcmT3oW+TO7hj/0yebt2UkSNHEh8fD2BFIgu56ohCRB4GWgKlROSzVE/lx3EYyhjjRSIvJfDhgmDm/XUcAP87CvHYbZF88HI7QkND6d27N8OHDydHjhweTmrSW1qHnk4Du3CckwhOtfwiMMCdoYwx6WvJrhO8O3cXEdEJ5PT1of/DVWlaNjsVKzSifPnyrF69mv/85z+ejmk85KqFQlV3ADtE5GdVjUvHTMaYdHI2Op735wezKOgEAPeVL8xzlZTWDcsDsGDBAho1akSuXLk8GdN4mCvnKEqJyHQRCRKRfX9/uT2ZMcatFgWdoPmYNSwKOkFuv2y89WBxWPE5bZo2+KeJX8uWLa1IGJeuepoCDAFGAa2A7tg5CmMyrTMX43l/3i4W7zoJwP3lC/OA7ubDrp2Ijo5myJAh1K9f38MpTUbiyogit6ouBVDVg6r6LmAzjhiTyagq8/46Rosxq1m86yR5/LIx5LG7YeU43uj9PFWqVOGvv/5i0KBB+Pr6ejquyUBcGVHEi4gAB0XkJeAYUNy9sYwxt9LpC3EMmruL33efAqBhhcIMe6ImZQrnIfHhFtSv/wB9+vSxJn7milwpFP8F8gKvAZ8ABYAe7gxljLk1VJU5O47x0YLdRMUmki9HdnrUyMHcLwawzKcrPXv2pHv37p6OaTK4axYKVf3T+e1FoAuAiJR2ZyhjzM07GRXHoDk7WbH3NAAPVijEHcdX8k6XIeTMmdNOUhuXpVkoRKQuUApYp6oRIlIdRyuPhwArFsZkQKrKjG3hfLxwNxfjksiXMzvPVRGmj36Nn7Zto3379owfP56SJUt6OqrJJK56MltEhgE/A52AJSIyCMecFIFA5fSJZ4y5HsfPx9Lt+y30nxnExbgkmlYtzu//bUS1AkmEhYUxY8YMZs2aZUXCXJe0RhTtgFqqGisihYHjzschrm5cRFoCY4FswCRVHX6FdZ4GPsQxx0Wgqj57HfmNMThGEdO3hPHJoj1ExydRIJcvHe+IoWDsVkoUqPtPE788efJ4OqrJhNIqFHGqGgugqudEZO91FolswHigORAObBGR+aq6O9U6lYCBQANVjRQRu5rKmOsUHhnDwNk7Wbs/AoDGd+bDd8evDProaypUqECPHj3IkSOHFQlzw9IqFHeKyN+txAUol+oxqvr4NbZ9H3BAVUMBRGQ6jlHK7lTrvACMV9VI5zZPX2d+Y7KslBRl2uajDAvYw6WEZArl9qVdsQimDO3D0aNH6dOnD0OHDrUmfuampVUonrjs8ZfXue1SQFiqx+E45t5OrTKAiKzHcXjqQ1VdcvmGRKQX0AugbNmy1xnDGO8Tdi6G/jOD2Bh6FoBWd5fgxToFqFuzNRUqVGDNmjU0bNjQwymNt0irKeCKm9y2XGmzV3j/SkBjHFdRrRWRuy+fo1tVJwITAfz9/W2+bpNlpaQoP246wogle4lJSKZwHj+eq5TC6x3rABAQEMCDDz5Izpw5PZzUeBNXWnjcqHCgTKrHpXGcEL98nXmqmqiqh4AQHIXDGHOZwxGX6PjtJj6YH0xMQjJNyvpSZvsE3nim5T9N/Jo3b25FwtxyrtyZfaO2AJVEpDyOth8dgcuvaJoLPANMEZGiOA5FhboxkzGZTkqKMmXDYUYu3UtcYgpF8vjS2GcP37/7ETExMQwdOtSa+Bm3crlQiEgOVY13dX1VTRKRV4ClOM4/TFbVYBEZDGxV1fnO51qIyG4gGeinqmev759gjPcKPRNN/5lBbD0SCUC72rdzdMZQPps9kwYNGjBp0iSqVq3q4ZTG24lq2of8ReQ+4DuggKqWFZFawPOq+mp6BLycv7+/bt261RNvbUy6SU5RJq87xKhlIcQnpVA0jy9DH69Ji+olmDp1KhcvXuTll1/Gx8edR4+NNxGRbarqfyOvdWVEMQ5og+MwEaoaKCLWZtwYNzlw+iL9Zgax46jjmo7GtyWwd8ZQjpbsDtWf57nnnvNwQpPVuFIofFT1iKPT+D+S3ZTHmCwrKTmFb9ceYszyfSQkpVA8T3ZqnFvNTwNGkydPHvLmzevpiCaLcqVQhDkPP6nzbutXAZsK1ZhbaN+pi/SbEUhgeBQAjYpEs+OnYUwOCuTJJ5/kiy++oESJEh5OabIqVwpFbxyHn8oCp4DlzmXGmJuUmJzCN6sPMm7FARKSUyhZICfDHq9B3KHtLDt9ilmzZvH449dqgmCMe7lSKJJUtaPbkxiTxew5cYF+MwPZdewCAA3zRXBv7gs0rtIUqrTk4MGD5M6d28MpjXGtUGwRkRDgV2C2ql50cyZjvFpCUgpfrTrA+JUHSExWSuRSSu2fw88/T2ZzpUr0eakXOXLksCJhMoxrXlunqhWAIUAdYKeIzBURG2EYcwOCj0fRbvx6Pl++n8RkpX6OcI5/14c5077n9ddfZ/v27dbEz2Q4Lt1wp6obgA0i8iHwOY4Jjaa7MZcxXiUhKYUv/9jPV6sOkpSilCmcizcfKMLTDz1GxYoVWbdund1dbTKsaxYKEcmLoz14R+AuYB5gP9HGuGhneBT9Zgay9+RFVJUWxaL5/NWHyZMjO4sXL6Zhw4bWn8lkaK6MKHYBC4CRqrrWzXmM8RrxScmMXb6fb9aEkpyilPCNJefmKUxatojOdUvSqFEjmjVr5umYxlyTK4XiTlVNcXsSY7zIX2Hn6TcjkP2nowHlnrhAVn0ziri4OEaMGEGDBg08HdEYl121UIjIaFV9C5glIv/TEMqFGe6MyXLiEpMZs3wf364JJUXhzqJ58Fk5hrkB83nwwQeZNGkSlStX9nRMY65LWiOKX53/vd6Z7YzJkrYdiaTfzEBCz1xCNJkXHqzAWw9X5bfiR3miTUtefPFFa+JnMqW0Zrjb7Pz2LlX9f8XC2T78ZmfAM8YrxCYkM3pZCN+tP4QqlNSzxCz/kuIVXyCnb3W6du3q6YjG3BRX/rzpcYVlPW91EGMyo82HztFq7BomrTsEyUlUPrGM7Z+/QPjhgxQoUMDT8Yy5JdI6R9EBxyWx5UVkdqqn8gHnr/wqY7KGmIQkRi4JYerGw45RROIJzi3+nN/3BNOhQwfGjRtH8eLFPR3TmFsirXMUm4GzOOa6Hp9q+UVghztDGZORbQo9S/+ZQRw9F0M2H+HlJhWonAgvTY9k7ty5tGvXztMRjbml0jpHcQg4hKNbrDFZ3qX4JEYs2csPG48AUPxSKM1LxPNWi0eAKjQ7cIBcuXJ5NqQxbpDWoafVqtpIRCKB1JfHCqCqWtjt6YzJINYfiODtWUGER8bikxjL7ftns37BL0RVrsz7fV8lR44cViSM10rr0NPf050WTY8gxmREF+MSGbZ4L9P+PApAschgwheMY+OpE7z55psMHjzYmvgZr5fWoae/78YuAxxX1QQRaQjUBH4CLqRDPmM8Zs2+MwyYFcTxqDh8swld7s7Lx10HUaVKFebOmUW9evU8HdGYdOFKC4+5QF0RqQD8ACwCpgFt3BnMGE+5EJfIJwv38OvWMFSVsknHmPTGs1QpkY8HSyyjQYMG+Pn5eTqmMenGlUKRoqqJIvI48LmqjhMRu+rJeKWVIad5Z/ZOTkTF4RMTSd5tU1i3YQUn21alSolGNGnS5NobMcbLuDQVqog8BXQBHnMu83VfJGPSX1RMIoMX7mbW9nBUlcLh6zi4cAInEuIZNWqUNfEzWZorhaIH8DKONuOhIlIe+MW9sYxJP8t3n+KdOTs5fTEev+w+5F07lh1rltKoUSMmTZpExYoVPR3RGI+6ZqFQ1V0i8hpQUUSqAgdU9RP3RzPGvSIvJfDRgmDm/nUcTUmmzh2F+fTp2myoEkHMs+154YUXrImfMbg2w92DwI/AMRz3UJQQkS6qut7d4Yxxl6XBJxk0ZxcR0fFI5FGyrZvIw6/1pkKxhlTo0sXT8YzJUFw59DQGeERVdwOIyF04Coe/O4MZ4w7nLiXwwfxgFgQeR5MTybtnIfuX/UCBAgUoUsTuITXmSlwpFH5/FwkAVd0jInZtoMl0Anae4L25uzh7KQGJCCVp5ZfsDt3Hs88+y+eff06xYsU8HdGYDMmVQrFdRL7BMYoA6IQ1BTSZSER0PO/P20XAzpMA3H9nYdr4JzNwaQwLFiygTRu7JciYtLhSKF4CXgP64zhHsQb4wp2hjLkVVJWFQSd4f94uImMS4fguHiway9TnP8DHR3iyTQty5szp6ZjGZHhpFgoRqQFUAOao6sj0iWTMzTt9MY735u5iafApUuIvkWP7LxxYM5dcVauSOGwgOXLksCJhjIuueu2fiLyDo31HJ+B3EbnSTHfGZCiqytwdx2gxZg1Lg0+hh7cS/fNrhK6bT9++fdm2bZs18TPmOqU1ougE1FTVSyJSDAgAJqdPLGOu36kLcQyas5Ple04DUKdoCgs++4SqVauydNEC6tat6+GExmROaRWKeFW9BKCqZ0TE7jwyGZKqMmv7MQYvCCYqNpHsEfsZ9tKTPOVfmtX+y6hfv7418TPmJqRVKO5MNVe2ABVSz52tqo9fa+Mi0hIYC2QDJqnq8Kus9yQwA6irqltdDW/MiahYBs7eyaqQMyRdiMBnwyRCA9dxW9d7ESlD48aNPR3RmEwvrULxxGWPv7yeDYtINhxzbTcHwoEtIjI/9T0ZzvXy4biq6s/r2b7J2lSV37aGMWThHi7EJZAU/DuRq76HlGQ+++wzGjZs6OmIxniNtCYuWnGT274PR1+oUAARmQ60A3Zftt7HwEig702+n8kijp2PZcCsINbujwBAln/G8e2reOihh/j222+58847PZzQGO/iyn0UN6oUEJbqcTjw/6YEE5F7gDKqulBErlooRKQX0AugbNmybohqMgNVZdrmowwL2MvF2HgK5vZj8GM1uFC9B/HxnejZsyci4umYxngddxaKK/3G6j9POk6OjwG6XWtDqjoRmAjg7++v11jdeKGwczEMmB3E+gNnSTh9iKRVX/Pq671pV7sl1LYmfsa4k8uFQkRyqGr8dWw7HMd8238rDRxP9TgfcDewyvlXYAlgvoi0tRPa5m8pKcrPfx5h2OK9XIqJI2HbLM6sm07hQoW4s8ztno5nTJbgSpvx+4DvgAJAWRGpBTyvqq9e46VbgErOiY6OAR2BZ/9+UlWjgKKp3mcV0NeKhPnbkbOXeHtWEJtCzxF/Yh/xK74k8lgoXbp0YcyYMRQpUsTTEY3JEly5N2Ic0AY4C6CqgcA1Jw5W1STgFWApsAf4TVWDRWSwiLS98cjG26WkKN+vP0TLz9eyKfQcRfL40ad+CfJlSyIgIIAffvjBioQx6ciVQ08+qnrkspOEya5sXFUDcNzRnXrZ+1dZt7Er2zTe7VDEJfrPDGTL4UhijwRSxTeSuV9/QuE8fvTr9ri13zDGA1wpFGHOw0/qvDfiVWCfe2OZrCbZOYr4dGkIsdEXiF03lYhtiyly113kyT4EwIqEMR7iSqHojePwU1ngFLDcucyYW+LgmWj6zQhk+9HzxOzfRMzKCcRGnaN///58+OGHViCM8bBrFgpVPY3jRLQ6AvtTAAAU9ElEQVQxt1RyijJpbSijf99HQlIKBVOiODZ/BNWq3cV3yxbj72+z7RqTEbhy1dO3pLr/4W+q2sstiUyWsP/URfrODOKvo5HEhwfT+bGWvNe6BYFtSnP//fdbEz9jMhBXDj0tT/V9TqA9//+Oa2NclpScwjdrQhm7fD8xkSe5tGIC5/dt5tFe91Mgty//+c9/PB3RGHMZVw49/Zr6sYj8CPzutkTGa+09eYF+M4IICo8kesdiotdOxTebMG7cOGviZ0wGdiMtPMoDd9zqIMZ7JSan8PWqg3zxx34Sk5XohcM5t3sDzZs3Z+LEiZQrV87TEY0xaXDlHEUk/56j8AHOAQPcGcp4j93HL9BvZiC7wiNBhM73l6Nitd6Q/DzdunWzJn7GZAJpFgpx/BbXwtGCAyBFVa0pn7mmhKQUxq88wPiVB4g5eZALy76gd69efNL+UaCGp+MZY65DmoVCVVVE5qhqnfQKZDK/Xcei6DsjkD3hZzm/4VeiN8+iSJHCNKhZ0dPRjDE3wJVzFJtF5F5V3e72NCZTi09K5osVB/h69UFiwvcStXQssaeP8txzz/HZZ59RuHBhT0c0xtyAqxYKEcnubOzXEHhBRA4Cl3DMM6Gqem86ZTSZQGDYefrNDGTfqWhEoEWlAqxaI0xcsoSHH37Y0/GMMTchrRHFZuBe4LF0ymIyobjEZD5fvp+Jaw5yKXQ7+WJPMn3cx/iXK0x8/87WfsMYL5BWoRAAVT2YTllMJrP9aCT9ZgSyL+wU5/+YRPTO5RStVp0aJfMA1sTPGG+RVqEoJiJvXu1JVf3MDXlMJhCXmMzoZSF8t+4Q0Xs3ELViAskxUQwcOJD333/fCoQxXiatQpENyMuV5742WdTWw+foPzOI0IhLpFw4zbmFn1Lj7ruZPPk77rnnHk/HM8a4QVqF4oSqDk63JCZDi01I5tOlIUxeH0rc0V3U8H+AT/s0IPrZStSrVw9fX19PRzTGuMk1z1EY82foWfrPCuJg6GHOLf2S2EPb+fH5FdQuUxDKWI8mY7xdWoWiabqlMBnSpfgkRi7Zy5QNh7i4fREX1vyAX3YfvvjiC5o2buzpeMaYdHLVQqGq59IziMlYNhyI4O3ZQYSdiyVi9hBiDmymeYsWfDtxInfcYT0hjclKbqR7rPFi0fFJDF+8hx/Xh4KPD9VvL0iT//bitrx96NKlizXxMyYLskJh/rFufwRvzwoidO9Ozi0ZR9unuzDtlffxzfagp6MZYzzICoXhQlwiwwL28PP6A0Rt+IWLm+dQpGhRujavg282H0/HM8Z4mBWKLG5VyGkGzt7J4d1/cTZgDInnjtGte3c+Gz2aQoUKeTqeMSYDsEKRRUXFJjJk4W5mbAsHoHyh7GTP68v3v/5Os2bNPJzOGJORWKHIgv7Ye8oxivhrAynnwvj4vQE837AVKaN64+fn5+l4xpgMxgpFFnI+JoHBC3YzY8MeIv+YxKVdf1Dlrur0eKAM2bP5QDYrEsaY/2WFIotYFnySd+bs5MjWP4hcPgHionln0CDef+89G0UYY9JkhcLLnbuUwIfzg5kfeJykqNOcXTiK6nfX4Kep31OrVi1PxzPGZAJWKLzYkl0nGDRnJ+G7t1Ko4j283bkxlTqt4v7765E9u/2vN8a4xj4tvNDZ6Hjenx/M3DU7OLfkS+KO/MW4eYvp0KA8UN7T8YwxmYwVCi+iqizaeYL35gRxZO1szq/5gRy+vowf/xVPtWnh6XjGmEzKCoWXOHMxnvfm7mJJ8ElOz/yI2INbeKj5w0z57lvKlCnj6XjGmEzMCkUmp6rMDzzO+3MCOR+XTN4cvvTs1pV65V6jU6dO1sTPGHPT3FooRKQlMBbHtKqTVHX4Zc+/CTwPJAFngB6qesSdmbzJ6QtxDJq7i4Ur1nF28VhqN3+S2V9+ROlCLT0dzRjjRdxWKEQkGzAeaA6EA1tEZL6q7k612g7AX1VjRKQ3MBLo4K5M3kJVmbPjGB/M3sHR5VO5sHkOhYoU5b2O/6F0odyejmeM8TLuHFHcBxxQ1VAAEZkOtAP+KRSqujLV+puAzm7M4xVORsXxzpydLF6xmohFY0iKPM6zXbsxfuwYChYs6Ol4xhgv5M5CUQoIS/U4HKiXxvo9gcVXekJEegG9AMqWLXur8mUqqsqMbeF8vHA3F+OSyOmTTJE8vvz0mzXxM8a4lzsLxZXOouoVVxTpDPgDja70vKpOBCYC+Pv7X3Eb3uz4+VgGzN7J0sUBJEQc5fHnejP0ndcpnOtNfH19PR3PGOPl3FkowoHU12WWBo5fvpKINAMGAY1UNd6NeTIdVWX6ljA+mrGJ8ICvubR7FeUqV+OrZ74mR44cno5njMki3Dl92RagkoiUFxE/oCMwP/UKInIP8A3QVlVPuzFLphMeGUOX7/7ktSFfsn/8C8SGrKPvgEGE7NxhRcIYk67cNqJQ1SQReQVYiuPy2MmqGiwig4Gtqjof+BTIC8xwXu9/VFXbuitTZpCSovy8+SjDA/YQdeYEZwM+p2LV6sycNpWaNWt6Op4xJgsS1cx1yN/f31+3bt3q6RhucfRsDP1nBrJy5R/kKlebR2qU4NESl2jRuAHZsmXzdDxjTCYmIttU1f9GXmt3ZmcAKSnKDxsP8/G0lRxbOJb4o0EM+24WAzrV8XQ0Y4yxQuFphyMu0W/GDlbMmML5tT/h6+vL6LFf8ka3xzwdzRhjACsUHpOcokzZcJhPl+7lyLT3iAvdxn2NmjPrp8mULl3a0/GMMeYfVig84OCZaPpO38b28AuI+PDQo0/Tvtbr9OzW2Zr4GWMyHCsU6Sg5RfluXShDvl/AyYWfU/L+Nnw74j2aV2vt6WjGGHNVVijSyYHTF/nvtM2snvYlF7fOJ2+hoozu8TDNq93m6WjGGJMmKxRulpScwrdrDzH0+zmcnD+apPMnebRDV378ZhwFChTwdDxjjLkmKxRuFHLyIv1nBhIYHkViQiL5cvnx46+/07qFNfEzxmQeVijcIDE5hW9WH2TohJ+IPXOUu1p0ZthHz9Pgzn5kz2673BiTudin1i2258QFXv1+NRt/Gk3MntUUL1+VBX2+pEj+PJ6OZowxN8SdTQGzlISkFMb8HkLjl4awckhnYvet5/nXBxC2N9CKhDEmU7MRxS2w61gU/WYGsXPvAU4vGkOpCtWYM/0H6t5Ty9PRjDHmptmI4iYkJKUwaskeWrw1jj0nLnBn+XJM+i2AI7u3W5EwxngNG1HcoKDw87z8VQBbfxpGfNguug2dwvg3OpHbz3apMca72KfadYpLTGbMsj2MGj2GyLU/4ZPdl0HDx/Fx/67WfsMY45WsUFyHHUcj6TcziPVfvkncoe1UrfcQC6dPoUK5Mtd+sTHGZFJWKFwQl5jMpwG7mLzxKIoPFRq2pfNbfXj75e42ijDGeD0rFNew7cg5eo2ezs5pI8h3Tyv6vvk6/23Wkpy+NuOcMSZrsEJxFbEJyQydv4NxI4ZwYet8chQsxkddmvJKq7s8Hc0YY9KVFYor2HzoHL0+/ZHgacNIijrFA22eYe6U8RQvUsjT0YwxJt1ZoUglJiGJkUtCmLrxMLGRMfj5+TFxxkK6P2nzRRhjsi4rFE4bD56l5+CvOHH4AEUadKB/98d58fs3yZMzh6ejGWOMR2X5QnEpPol3f1nHxOHvEROyjvylKzNjyijuKV/M09GMMSZDyNItPNbtP0PtLu8xrndbYg5sonX3/3J8X5AVCWOMSSVLjiguxiUybPFefli2lWOzR1GobFV+mPI9bf7j7+loxhiT4WS5QrFq7yl6D59MbIma5Cp8G/2++JXBPR8lp5+vp6MZY0yGlGUKxYW4RN6auJgfP32H+PBgHnhtHN8P7EaVEvk8Hc0YYzK0LFEolu86To++HxC2fCo+vjno8vYIvhvyMr7Z7e5qY4y5Fq8uFFExiQxeuJuv3u5O3OEdlKzViFk/TeKBuyt6OpoxxmQaXlsoAnYc4YOFezlzKYlCdVrRtkdPxg96mWw+1sTPGGOuh9ddHht5KYGnP/qeds0acnD1bPzvKMS6rwcy4b0+ViSMMeYGeNWIYs7mg7z4el/ObJpH9gLF6Na6AZ+++IAVCGOMuQleUSjORsfz/IgfWDDuXZIvnKFikyeYO/lLqpe7zdPRjDEm08v0hWJR0Anen7eLYwfPks0vBwO+/o3BvZ7Ax0YRxhhzS2TaQhERHU/nd8fx545dFHjgaZo0bszQz/tQvrjdF2GMMbeSW09mi0hLEQkRkQMiMuAKz+cQkV+dz/8pIuVc2e7UFX9RsV4zlo7tT9z+jXzYujI/P1/PioQxxriBqKp7NiySDdgHNAfCgS3AM6q6O9U6LwM1VfUlEekItFfVDmltN1+x2zXm4gVSkhKo3e4FZn89lPLFC7jl32CMMd5CRLap6g01tHPniOI+4ICqhqpqAjAdaHfZOu2Aqc7vZwJNRSTNkwvRESfJWbwco39ZyvaZX1qRMMYYN3PnOYpSQFiqx+FAvauto6pJIhIFFAEiUq8kIr2AXs6H8TFhwbveevoh3nJL7EylKJftqyzM9sW/bF/8y/bFv6rc6AvdWSiuNDK4/DiXK+ugqhOBiQAisvVGh0/exvbFv2xf/Mv2xb9sX/xLRLbe6GvdeegpHCiT6nFp4PjV1hGR7EAB4JwbMxljjLlO7iwUW4BKIlJeRPyAjsD8y9aZDzzn/P5J4A9119l1Y4wxN8Rth56c5xxeAZYC2YDJqhosIoOBrao6H/gO+FFEDuAYSXR0YdMT3ZU5E7J98S/bF/+yffEv2xf/uuF94bbLY40xxngHr+sea4wx5tayQmGMMSZNGbZQuKv9R2bkwr54U0R2i0iQiKwQkTs8kTM9XGtfpFrvSRFREfHaSyNd2Rci8rTzZyNYRKald8b04sLvSFkRWSkiO5y/J494Iqe7ichkETktIruu8ryIyDjnfgoSkXtd2rCqZrgvHCe/DwJ3An5AIFDtsnVeBiY4v+8I/Orp3B7cF02A3M7ve2flfeFcLx+wBtgE+Hs6twd/LioBO4BCzsfFPZ3bg/tiItDb+X014LCnc7tpX/wHuBfYdZXnHwEW47iH7X7gT1e2m1FHFG5p/5FJXXNfqOpKVY1xPtyE454Vb+TKzwXAx8BIIC49w6UzV/bFC8B4VY0EUNXT6ZwxvbiyLxTI7/y+AP97T5dXUNU1pH0vWjvgB3XYBBQUkZLX2m5GLRRXav9R6mrrqGoS8Hf7D2/jyr5IrSeOvxi80TX3hYjcA5RR1YXpGcwDXPm5qAxUFpH1IrJJRFqmW7r05cq++BDoLCLhQADwavpEy3Cu9/MEyLjzUdyy9h9ewOV/p4h0BvyBRm5N5Dlp7gsR8QHGAN3SK5AHufJzkR3H4afGOEaZa0XkblU97+Zs6c2VffEMMEVVR4vIAzju37pbVVPcHy9DuaHPzYw6orD2H/9yZV8gIs2AQUBbVY1Pp2zp7Vr7Ih9wN7BKRA7jOAY730tPaLv6OzJPVRNV9RAQgqNweBtX9kVP4DcAVd0I5MTRMDCrcenz5HIZtVBY+49/XXNfOA+3fIOjSHjrcWi4xr5Q1ShVLaqq5VS1HI7zNW1V9YaboWVgrvyOzMVxoQMiUhTHoajQdE2ZPlzZF0eBpgAicheOQnEmXVNmDPOBrs6rn+4HolT1xLVelCEPPan72n9kOi7ui0+BvMAM5/n8o6ra1mOh3cTFfZEluLgvlgItRGQ3kAz0U9WznkvtHi7ui7eAb0XkvzgOtXTzxj8sReQXHIcaizrPx3wA+AKo6gQc52ceAQ4AMUB3l7brhfvKGGPMLZRRDz0ZY4zJIKxQGGOMSZMVCmOMMWmyQmGMMSZNViiMMcakyQqFyXBEJFlE/kr1VS6NdctdrVPmdb7nKmf30UBny4sqN7CNl0Skq/P7biJye6rnJolItVucc4uI1HbhNW+ISO6bfW+TdVmhMBlRrKrWTvV1OJ3et5Oq1sLRbPLT632xqk5Q1R+cD7sBt6d67nlV3X1LUv6b8ytcy/kGYIXC3DArFCZTcI4c1orIdudX/SusU11ENjtHIUEiUsm5vHOq5d+ISLZrvN0aoKLztU2dcxjsdPb6z+FcPlz+nQNklHPZhyLSV0SexNFz62fne+ZyjgT8RaS3iIxMlbmbiHxxgzk3kqqhm4h8LSJbxTH3xEfOZa/hKFgrRWSlc1kLEdno3I8zRCTvNd7HZHFWKExGlCvVYac5zmWngeaqei/QARh3hde9BIxV1do4PqjDne0aOgANnMuTgU7XeP9HgZ0ikhOYAnRQ1Ro4Ohn0FpHCQHuguqrWBIakfrGqzgS24vjLv7aqxqZ6eibweKrHHYBfbzBnSxxtOv42SFX9gZpAIxGpqarjcPTyaaKqTZytPN4Fmjn35VbgzWu8j8niMmQLD5PlxTo/LFPzBb50HpNPxtG36HIbgUEiUhqYrar7RaQpUAfY4mxvkgtH0bmSn0UkFjiMow11FeCQqu5zPj8V6AN8iWOui0kisghwuaW5qp4RkVBnn539zvdY79zu9eTMg6NdReoZyp4WkV44fq9L4pigJ+iy197vXL7e+T5+OPabMVdlhcJkFv8FTgG1cIyE/2dSIlWdJiJ/Aq2BpSLyPI62ylNVdaAL79EpdQNBEbni/CbO3kL34Wgy1xF4BXjoOv4tvwJPA3uBOaqq4vjUdjknjlnchgPjgcdFpDzQF6irqpEiMgVH47vLCfC7qj5zHXlNFmeHnkxmUQA44Zw/oAuOv6b/HxG5Ewh1Hm6Zj+MQzArgSREp7lynsLg+p/heoJyIVHQ+7gKsdh7TL6CqAThOFF/pyqOLONqeX8ls4DEccyT86lx2XTlVNRHHIaT7nYet8gOXgCgRuQ1odZUsm4AGf/+bRCS3iFxpdGbMP6xQmMziK+A5EdmE47DTpSus0wHYJSJ/AVVxTPm4G8cH6jIRCQJ+x3FY5ppUNQ5Hd80ZIrITSAEm4PjQXejc3moco53LTQEm/H0y+7LtRgK7gTtUdbNz2XXndJ77GA30VdVAHPNjBwOTcRzO+ttEYLGIrFTVMziuyPrF+T6bcOwrY67KuscaY4xJk40ojDHGpMkKhTHGmDRZoTDGGJMmKxTGGGPSZIXCGGNMmqxQGGOMSZMVCmOMMWn6P2jjPLPcx4TxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a1a3a0908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084628591210464"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name-name2'"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [('name', 2), ('name2', 3)]\n",
    "#names = list(zip(*a))[0]\n",
    "suffix = '-'.join([name for name, _ in a])\n",
    "suffix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1}, {'b': 2}, {'c': 3, 'd': 4}]"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def which_set(sets, k):\n",
    "    for i in range(len(sets)):\n",
    "        if k in sets[i]:\n",
    "            return i\n",
    "    return len(sets)\n",
    "\n",
    "def split_dict(d, *key_sets):\n",
    "    ret = [{} for _ in range(len(key_sets) + 1)]\n",
    "    \n",
    "    for k, v in d.items():\n",
    "        ret[which_set(key_sets, k)][k] = v\n",
    "    \n",
    "    return ret\n",
    "    \n",
    "d = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
    "ret = split_dict(d, ('a',), ('b',))\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=0.7, max_features=None, min_df=1,\n",
       "        ngram_range=(5, 5), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...nalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(clf__C=30.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': LogisticRegression(C=30.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'clf__C': 30.0,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__dual': False,\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__intercept_scaling': 1,\n",
       " 'clf__max_iter': 100,\n",
       " 'clf__multi_class': 'ovr',\n",
       " 'clf__n_jobs': 1,\n",
       " 'clf__penalty': 'l1',\n",
       " 'clf__random_state': 0,\n",
       " 'clf__solver': 'liblinear',\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False,\n",
       " 'memory': None,\n",
       " 'std': StandardScaler(copy=True, with_mean=False, with_std=True),\n",
       " 'std__copy': True,\n",
       " 'std__with_mean': False,\n",
       " 'std__with_std': True,\n",
       " 'steps': [('vect',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=False, max_df=0.7, max_features=None, min_df=1,\n",
       "           ngram_range=(5, 5), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "           stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "           token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function MemoCV.tokenizer at 0x7f6a39a567b8>,\n",
       "           use_idf=True, vocabulary=None)),\n",
       "  ('std', StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
       "  ('clf',\n",
       "   LogisticRegression(C=30.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "             penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
       "             verbose=0, warm_start=False))],\n",
       " 'vect': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=False, max_df=0.7, max_features=None, min_df=1,\n",
       "         ngram_range=(5, 5), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function MemoCV.tokenizer at 0x7f6a39a567b8>,\n",
       "         use_idf=True, vocabulary=None),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': False,\n",
       " 'vect__max_df': 0.7,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (5, 5),\n",
       " 'vect__norm': 'l2',\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__smooth_idf': True,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__sublinear_tf': False,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.MemoCV.tokenizer>,\n",
       " 'vect__use_idf': True,\n",
       " 'vect__vocabulary': None}"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-674-2ebe09ea40e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "{} * 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
